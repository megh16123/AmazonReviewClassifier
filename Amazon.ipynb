{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c2bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "import tensorflow as tf\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9acaab5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d43c7ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./sets\\dataset\\dataset.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c792e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['rating','title','reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2478bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews'] = df['reviews']+df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b14fccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('title',axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40fab985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('amazon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c02c5235",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f4b90bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(content):\n",
    "    content = str(content)\n",
    "    content = re.sub('[^A-Za-z]',' ',content)\n",
    "    content = re.sub('[\\\"\\'\\|\\?\\=\\.\\@\\#\\*\\,]',' ',content)\n",
    "    lemmed_content = content.lower()\n",
    "    lemmed_content = lemmed_content.split()\n",
    "    lemmed_content = [lemmatizer.lemmatize(word) for word in lemmed_content if not word in stopwords.words('english')]\n",
    "    lemmed_content = '  '.join(lemmed_content)\n",
    "    return lemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "538234c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviews_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>My lovely Pat has one of the GREAT voices of h...</td>\n",
       "      <td>lovely  pat  one  great  voice  generation  li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Despite the fact that I have only played a sma...</td>\n",
       "      <td>despite  fact  played  small  portion  game  m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I bought this charger in Jul 2003 and it worke...</td>\n",
       "      <td>bought  charger  jul  worked  ok  design  nice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Check out Maha Energy's website. Their Powerex...</td>\n",
       "      <td>check  maha  energy  website  powerex  mh  c  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Reviewed quite a bit of the combo players and ...</td>\n",
       "      <td>reviewed  quite  bit  combo  player  hesitant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>1</td>\n",
       "      <td>We bought this Thomas for our son who is a hug...</td>\n",
       "      <td>bought  thomas  son  huge  thomas  fan  huge  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>1</td>\n",
       "      <td>My son recieved this as a birthday gift 2 mont...</td>\n",
       "      <td>son  recieved  birthday  gift  month  ago  lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399997</th>\n",
       "      <td>1</td>\n",
       "      <td>I bought this toy for my son who loves the \"Th...</td>\n",
       "      <td>bought  toy  son  love  thomas  toy  need  one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>2</td>\n",
       "      <td>This is a compilation of a wide range of Mitfo...</td>\n",
       "      <td>compilation  wide  range  mitford  article  be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>1</td>\n",
       "      <td>This DVD will be a disappointment if you get i...</td>\n",
       "      <td>dvd  disappointment  get  hoping  see  substan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating                                            reviews  \\\n",
       "0            2  My lovely Pat has one of the GREAT voices of h...   \n",
       "1            2  Despite the fact that I have only played a sma...   \n",
       "2            1  I bought this charger in Jul 2003 and it worke...   \n",
       "3            2  Check out Maha Energy's website. Their Powerex...   \n",
       "4            2  Reviewed quite a bit of the combo players and ...   \n",
       "...        ...                                                ...   \n",
       "399995       1  We bought this Thomas for our son who is a hug...   \n",
       "399996       1  My son recieved this as a birthday gift 2 mont...   \n",
       "399997       1  I bought this toy for my son who loves the \"Th...   \n",
       "399998       2  This is a compilation of a wide range of Mitfo...   \n",
       "399999       1  This DVD will be a disappointment if you get i...   \n",
       "\n",
       "                                              reviews_new  \n",
       "0       lovely  pat  one  great  voice  generation  li...  \n",
       "1       despite  fact  played  small  portion  game  m...  \n",
       "2       bought  charger  jul  worked  ok  design  nice...  \n",
       "3       check  maha  energy  website  powerex  mh  c  ...  \n",
       "4       reviewed  quite  bit  combo  player  hesitant ...  \n",
       "...                                                   ...  \n",
       "399995  bought  thomas  son  huge  thomas  fan  huge  ...  \n",
       "399996  son  recieved  birthday  gift  month  ago  lov...  \n",
       "399997  bought  toy  son  love  thomas  toy  need  one...  \n",
       "399998  compilation  wide  range  mitford  article  be...  \n",
       "399999  dvd  disappointment  get  hoping  see  substan...  \n",
       "\n",
       "[400000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df9c2a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews_new'] = df['reviews'].apply(lemmatize)\n",
    "df.to_csv('lemma_amazon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bb584d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('lemma_amazon.csv')\n",
    "df = df.drop([df.columns[0],'reviews'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "53576593",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7dff519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = df[df['rating']==1]\n",
    "positive = df[df['rating']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "33b07634",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_train = negative.sample(frac=0.50,random_state=12)\n",
    "negative_test = negative.drop(negative_train.index)\n",
    "positive_train = positive.sample(frac=0.50,random_state=12)\n",
    "positive_test = negative.drop(negative_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "28859486",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.concat([positive_train,negative_train])\n",
    "test_set = pd.concat([positive_test,negative_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1d7f81b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer(content):\n",
    "    content = content.split()\n",
    "    content = set(content)\n",
    "    content = list(content)\n",
    "    content = '  '.join(content)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f7921b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['reviews_new'] = train_set['reviews_new'].apply(reducer)\n",
    "test_set['reviews_new'] = test_set['reviews_new'].apply(reducer)\n",
    "train_set.to_csv('train_amazon.csv',index=False)\n",
    "test_set.to_csv('test_amazon.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e4062126",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_amazon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1fd9e41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the data and label\n",
    "X = train_data['reviews_new'].values\n",
    "Y = train_data['rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9842399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X)\n",
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bd444a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199994"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc2eb2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b657d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 5000\n",
    "for i in range(0,X.shape[0],step):\n",
    "   train_input_X = X[i:i+step].toarray()\n",
    "   train_input_Y = Y[i:i+step]\n",
    "   model.partial_fit(train_input_X,train_input_Y,classes=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49d4d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazonmodel = open('amazonmodel_original.pkl','wb')\n",
    "pickle.dump(model,amazonmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1955f7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazonmodel = open('amazonmodel_original.pkl','rb')\n",
    "model = pickle.load(amazonmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "979f507c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c42a04f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>giving  disc  p  player  recorder  stopped  go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>topic  done  format  book  enjoyed  firstly  e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>access  want  listen  duke  gimmick  orchestra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>open  package  smell  dont  worn  able  havent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>install  brain  everything  beautifully  purch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199989</th>\n",
       "      <td>1</td>\n",
       "      <td>stuff  going  dont  cheap  knew  never  person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199990</th>\n",
       "      <td>1</td>\n",
       "      <td>maybe  book  lucky  casino  others  began  tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199991</th>\n",
       "      <td>1</td>\n",
       "      <td>upset  package  son  else  retire  better  cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199992</th>\n",
       "      <td>1</td>\n",
       "      <td>meant  kitchen  officially  train  fall  birth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199993</th>\n",
       "      <td>1</td>\n",
       "      <td>comedy  otherwise  basically  heard  elsewhere...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199994 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating                                        reviews_new\n",
       "0            1  giving  disc  p  player  recorder  stopped  go...\n",
       "1            1  topic  done  format  book  enjoyed  firstly  e...\n",
       "2            1  access  want  listen  duke  gimmick  orchestra...\n",
       "3            1  open  package  smell  dont  worn  able  havent...\n",
       "4            1  install  brain  everything  beautifully  purch...\n",
       "...        ...                                                ...\n",
       "199989       1  stuff  going  dont  cheap  knew  never  person...\n",
       "199990       1  maybe  book  lucky  casino  others  began  tho...\n",
       "199991       1  upset  package  son  else  retire  better  cou...\n",
       "199992       1  meant  kitchen  officially  train  fall  birth...\n",
       "199993       1  comedy  otherwise  basically  heard  elsewhere...\n",
       "\n",
       "[199994 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test_amazon.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28ba1a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data['reviews_new'].values\n",
    "Y_test = test_data['rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90c6778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76e8da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 5000\n",
    "score = []\n",
    "for i in range(0,X_test.shape[0],step):\n",
    "   test_input_X = X_test[i:i+step].toarray()\n",
    "   test_input_Y = Y_test[i:i+step]\n",
    "   score.append(model.predict(test_input_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc606b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for i in score:\n",
    "    predicted = predicted+list(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "258f5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.asarray(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89159a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data_file = open('score_amazon.pkl','wb')\n",
    "pickle.dump(predicted,predicted_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "900510eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data_file = open('score_amazon.pkl','rb')\n",
    "predicted_data = pickle.load(predicted_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8e8df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_accuracy = accuracy_score(predicted_data,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01f29f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8724761742852286"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7d5f31ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your text to be predicted This is a great product. Rreally liked it\n",
      "It is a positive review\n"
     ]
    }
   ],
   "source": [
    "text = input(\"Enter your text to be predicted \")\n",
    "text = lemmatize(text)\n",
    "X_to_be_predicted = vectorizer.transform([text])\n",
    "prediction = model.predict(X_to_be_predicted.toarray())\n",
    "if prediction[0] == 1:\n",
    "    print('It is a negative review')\n",
    "elif prediction[0]==2:\n",
    "    print('It is a positive review')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
